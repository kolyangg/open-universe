# configuration for Universe++ network with HiFi-GAN loss
_target_: open_universe.networks.universe.UniverseGAN

fs: 16000

normalization_norm: 2
normalization_kwargs:
  ref: both
  level_db: -26.0

edm:
  noise: 0.25

score_model:
  _target_: open_universe.networks.universe.ScoreNetwork
  fb_kernel_size: 3
  rate_factors: [2, 4, 4, 5]
  n_channels: 32
  n_rff: 32
  noise_cond_dim: 512
  encoder_gru_conv_sandwich: false
  extra_conv_block: true
  decoder_act_type: prelu
  use_weight_norm: true
  use_antialiasing: true
  time_embedding: simple

condition_model:
  _target_: open_universe.networks.universe.ConditionerNetwork
  fb_kernel_size: ${model.score_model.fb_kernel_size}
  rate_factors: ${model.score_model.rate_factors}
  n_channels: ${model.score_model.n_channels}
  n_mels: 80
  n_mel_oversample: 4
  encoder_gru_residual: true
  extra_conv_block: ${model.score_model.extra_conv_block}
  decoder_act_type: prelu
  use_weight_norm: ${model.score_model.use_weight_norm}
  use_antialiasing: false
  text_encoder_config:
    _target_: open_universe.networks.universe.TextEncoder ### NEW ###
    # vocab_size: 1000
    # embed_dim: 256
    # hidden_dim: 512
    # num_layers: 1
    hidden_dim: 256 # 512 # 256

diffusion:
  schedule: geometric
  sigma_min: 0.0005
  sigma_max: 5.0
  n_steps: 8
  epsilon: 1.3

losses:
  multi_period_discriminator:
    mpd_reshapes: [2, 3, 5, 7, 11]
    use_spectral_norm: false
    discriminator_channel_mult: 1
  multi_resolution_discriminator:
    resolutions: [[1024, 120, 600], [2048, 240, 1200], [512, 50, 240]]
    use_spectral_norm: false
    discriminator_channel_mult: 1
  disc_freeze_step: 0
  weights:
    mel_l1: 45.0 #  60.0 # increased from 45.0 for stronger reconstruction
    score: 1.0
  use_signal_decoupling: true
  signal_decoupling_act: snake
  score_loss:
    _target_: torch.nn.MSELoss

training:
  audio_len: ${datamodule.datasets.vb-train-16k.audio_len}
  time_sampling: time_normal_0.95
  dynamic_mixing: false
  ema_decay: 0.999

validation:
  main_loss: val/score # val/pesq # val/pesq default
  main_loss_mode: max
  n_bins: 5
  max_enh_batches: 4
  enh_losses:
    val/:
      _target_: open_universe.metrics.EvalMetrics
      audio_fs: ${model.fs}

optimizer:
  accumulate_grad_batches: 1
  generator:
    _target_: torch.optim.AdamW
    lr: 0.0002 # 0.0004  # increased generator learning rate from 0.0002
    weight_decay: 0.01
    betas: [0.8, 0.99]
    weight_decay_exclude: [prelu, bias]
  discriminator:
    _target_: torch.optim.AdamW
    lr: 0.0002
    betas: [0.8, 0.99]
  grad_clip_vals:
    mrd: 1000.0
    mpd: 1000.0
    score: 1000.0
    cond: 1000.0

scheduler:
  generator:
    scheduler:
      _target_: open_universe.utils.schedulers.LinearWarmupCosineAnnealingLR
      T_warmup: 20000
      T_cosine: 400000
      eta_min: 1.6e-06
      T_max: ${trainer.max_steps}
    interval: step
    frequency: 1
  discriminator:
    scheduler:
      _target_: open_universe.utils.schedulers.LinearWarmupCosineAnnealingLR
      T_warmup: 20000
      T_cosine: 400000
      eta_min: 1.6e-06
      T_max: ${trainer.max_steps}
    interval: step
    frequency: 1

grad_clipper:
  _target_: open_universe.utils.FixedClipper
  max_norm: 1000.0
